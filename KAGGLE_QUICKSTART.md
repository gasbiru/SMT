# üöÄ Guia R√°pido: Rodando SMT no Kaggle

## üìã Pr√©-requisitos
- Conta no Kaggle
- Notebook com **2x GPUs** (T4 ou P100)
- **30GB RAM**

## üéØ Passos para Usar

### 1Ô∏è‚É£ Criar Novo Notebook no Kaggle
1. Acesse [kaggle.com/code](https://www.kaggle.com/code)
2. Clique em **"New Notebook"**
3. Configure:
   - **Accelerator**: GPU T4 x2 ou GPU P100 x2
   - **Internet**: ON (para clonar reposit√≥rio)

### 2Ô∏è‚É£ Upload do Notebook
1. No Kaggle, clique em **File ‚Üí Upload Notebook**
2. Selecione `kaggle_training_notebook.ipynb` deste reposit√≥rio
3. Ou copie manualmente o conte√∫do das c√©lulas

### 3Ô∏è‚É£ Executar C√©lulas Sequencialmente

#### C√©lula 1: Instalar Depend√™ncias (‚è±Ô∏è ~2 min)
```python
# Instala todas as bibliotecas necess√°rias
# J√° otimizado para usar PyTorch nativo do Kaggle
```

#### C√©lula 2: Clonar Reposit√≥rio (‚è±Ô∏è ~30 seg)
```python
# Clona este reposit√≥rio com c√≥digo otimizado
# Detecta automaticamente pasta SMT existente
```

#### C√©lula 3: Verificar Configura√ß√µes (‚è±Ô∏è ~5 seg)
```python
# Verifica se configs existem
# Se n√£o, cria automaticamente com valores otimizados
```

#### C√©lula 4: Baixar Dataset (‚è±Ô∏è ~3-5 min)
```python
# Baixa PRAIG/grandstaff do HuggingFace
# ~455MB de dados
```

#### C√©lula 5: TESTE - Processar 5 Amostras (‚è±Ô∏è ~30 seg) ‚ö†Ô∏è IMPORTANTE
```python
# TESTE CR√çTICO antes do treinamento completo
# Se falhar aqui, n√£o prossiga!
```

#### C√©lula 6: Treinamento Completo (‚è±Ô∏è ~2-6 horas)
```python
# Treina o modelo SMT com:
# - DDP (2 GPUs)
# - Mixed precision
# - Gradient accumulation
# - Early stopping
```

### 4Ô∏è‚É£ Monitoramento

Durante o treinamento, voc√™ ver√°:
```
Epoch X/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| steps/steps [XX:XX<XX:XX, X.XXit/s]
Train Loss: X.XXX | Val Loss: X.XXX | Val CER: XX.XX%
```

Checkpoints salvos em `/kaggle/working/logs/version_X/checkpoints/`

## ‚ö†Ô∏è Problemas Comuns

### ‚ùå Erro: "Map operation frozen at 9%"
**Causa:** `num_proc` > 0 ativa multiprocessing com serializa√ß√£o defeituosa

**Solu√ß√£o:** J√° aplicada! Usamos `num_proc=None` em todas as configs

### ‚ùå Erro: "CUDA out of memory"
**Solu√ß√£o:** 
- Reduzir `batch_size` de 2 para 1 em `kaggle_config.json`
- Ou aumentar `reduce_ratio` para 0.3 (reduz tamanho das imagens)

### ‚ùå Erro: "numpy/scipy version mismatch"
**Solu√ß√£o:** J√° aplicada! For√ßamos numpy==1.26.4 e scipy==1.11.4 na c√©lula 1

## üìä Resultados Esperados

Ap√≥s o treinamento completo:
- **CER (Character Error Rate)**: ~5-15% (menor √© melhor)
- **Train Loss**: ~0.5-1.5
- **Val Loss**: ~0.8-2.0

Checkpoints salvos:
- `best-checkpoint.ckpt`: Melhor modelo (menor val_loss)
- `last-checkpoint.ckpt`: √öltimo checkpoint

## üéì Pr√≥ximos Passos

1. **Baixar Checkpoints**: 
   - No Kaggle, v√° para Output ‚Üí Download checkpoint
   
2. **Fazer Infer√™ncia**:
   - Use o modelo salvo para transcrever novas partituras
   
3. **Fine-tuning**:
   - Ajuste `config/FP-GrandStaff/kaggle_finetuning.json`
   - Carregue checkpoint do pr√©-treinamento

## üêõ Debug Local (Opcional)

Se quiser testar localmente antes de subir no Kaggle:

```bash
# Configure cache para disco F: (se tiver espa√ßo)
set HF_HOME=F:/huggingface_cache

# Execute teste local
python test_local.py
```

Isso testa:
1. Convers√£o PIL ‚Üí numpy
2. cv2.resize funciona
3. Dataset PRAIG/grandstaff carrega
4. Processamento de amostra funciona

## üìö Documenta√ß√£o Adicional

- **README.md**: Vis√£o geral do projeto SMT
- **CONTRIBUTING.md**: Guia para contribuir
- **config/**: Arquivos de configura√ß√£o com par√¢metros detalhados

## üÜò Suporte

Se encontrar problemas:
1. Verifique a se√ß√£o "Diagn√≥stico" no notebook
2. Leia os coment√°rios nas c√©lulas de c√≥digo
3. Abra uma issue no GitHub com logs completos

---

**√öltima atualiza√ß√£o**: 2024
**Testado em**: Kaggle (GPU T4 x2, 30GB RAM)
