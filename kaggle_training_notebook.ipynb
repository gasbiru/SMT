{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1439519",
   "metadata": {},
   "source": [
    "# üéµ SMT (Sheet Music Transformer) - Treinamento Otimizado para Kaggle\n",
    "\n",
    "Este notebook est√° otimizado para treinar o modelo SMT no Kaggle com:\n",
    "- **2x GPUs Tesla P100/T4**\n",
    "- **30GB RAM**\n",
    "- **Otimiza√ß√µes de mem√≥ria e performance**\n",
    "\n",
    "## üìã Configura√ß√µes Aplicadas\n",
    "\n",
    "‚úÖ **Otimiza√ß√µes de Performance:**\n",
    "- `num_proc=1` (evita overhead de multiprocessing)\n",
    "- `num_workers=4` (balanceado para 2 GPUs)\n",
    "- `batch_size=2` com gradient accumulation (batch efetivo = 16)\n",
    "- Cache habilitado nos datasets\n",
    "- Mixed precision training (16-bit)\n",
    "- DDP Strategy para multi-GPU\n",
    "\n",
    "‚úÖ **Otimiza√ß√µes de Mem√≥ria:**\n",
    "- `reduce_ratio=0.5` (reduz tamanho das imagens)\n",
    "- `writer_batch_size=100` (reduzido de 500)\n",
    "- Garbage collection autom√°tico\n",
    "- Gradient clipping habilitado\n",
    "\n",
    "## üöÄ Vamos come√ßar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cffe6e",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Instala√ß√£o de Depend√™ncias\n",
    "\n",
    "Primeiro, vamos instalar todas as bibliotecas necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f711783",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instalar depend√™ncias principais\n",
    "!pip install -q fire gin_config lightning loguru musicdiff numpy opencv-python-headless Pillow\n",
    "!pip install -q rich scikit-image timm torch torchinfo torchvision transformers datasets\n",
    "\n",
    "# Instalar depend√™ncias para gera√ß√£o sint√©tica\n",
    "!pip install -q verovio cairosvg names wonderwords\n",
    "\n",
    "# Verificar GPUs dispon√≠veis\n",
    "import torch\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"üéÆ Number of GPUs: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbb29f",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clonar o Reposit√≥rio e Preparar Ambiente\n",
    "\n",
    "Vamos clonar o c√≥digo do SMT e configurar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone o reposit√≥rio e fa√ßa pull das √∫ltimas altera√ß√µes\n",
    "!git clone https://github.com/gasbiru/SMT.git\n",
    "%cd SMT\n",
    "\n",
    "# Atualizar com √∫ltimas altera√ß√µes do remoto\n",
    "!git pull origin main\n",
    "\n",
    "# Criar diret√≥rios necess√°rios\n",
    "!mkdir -p /kaggle/working/checkpoints\n",
    "!mkdir -p vocab\n",
    "\n",
    "# Verificar estrutura\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc5fbc",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configura√ß√£o Otimizada para Kaggle\n",
    "\n",
    "Vamos criar a configura√ß√£o JSON otimizada para o ambiente Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c785a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Configura√ß√£o otimizada para Kaggle com 2 GPUs e 30GB RAM\n",
    "kaggle_config = {\n",
    "    \"data\": {\n",
    "        \"data_path\": \"antoniorv6/full-page-grandstaff\",\n",
    "        \"batch_size\": 2,  # Batch por GPU (total = 2*2 = 4)\n",
    "        \"vocab_name\": \"FP_GrandStaff_BeKern\",\n",
    "        \"num_workers\": 4,  # Otimizado para 2 GPUs\n",
    "        \"krn_format\": \"bekern\",\n",
    "        \"reduce_ratio\": 0.5  # Reduz imagens pela metade para economizar mem√≥ria\n",
    "    },\n",
    "    \"checkpoint\": {\n",
    "        \"filename\": \"SMT-Kaggle-best\",\n",
    "        \"monitor\": \"val_SER\",\n",
    "        \"dirpath\": \"/kaggle/working/checkpoints/\",\n",
    "        \"mode\": \"min\",\n",
    "        \"save_top_k\": 2,\n",
    "        \"verbose\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar configura√ß√£o\n",
    "with open('config/FP-GrandStaff/kaggle_config.json', 'w') as f:\n",
    "    json.dump(kaggle_config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Configura√ß√£o criada:\")\n",
    "print(json.dumps(kaggle_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31825cdc",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Monitoramento de Recursos\n",
    "\n",
    "Vamos verificar o uso de mem√≥ria antes de come√ßar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Verificar RAM dispon√≠vel\n",
    "ram = psutil.virtual_memory()\n",
    "print(f\"üíæ RAM Total: {ram.total / 1024**3:.2f} GB\")\n",
    "print(f\"üíæ RAM Dispon√≠vel: {ram.available / 1024**3:.2f} GB\")\n",
    "print(f\"üíæ RAM Usada: {ram.percent}%\")\n",
    "\n",
    "# Limpar mem√≥ria GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nüéÆ GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"   Mem√≥ria Alocada: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"   Mem√≥ria Reservada: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"   Mem√≥ria Livre: {(torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_allocated(i)) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f12b4f",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Teste R√°pido de Carregamento de Dados\n",
    "\n",
    "Antes de treinar, vamos testar se o dataset carrega corretamente com as otimiza√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datasets\n",
    "from data import prepare_fp_data\n",
    "\n",
    "# Teste de carregamento com otimiza√ß√µes\n",
    "print(\"üì• Testando carregamento do dataset...\")\n",
    "test_ds = datasets.load_dataset(\n",
    "    \"antoniorv6/full-page-grandstaff\", \n",
    "    split=\"train[:10]\",  # Apenas 10 amostras para teste\n",
    "    trust_remote_code=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset carregado: {len(test_ds)} amostras\")\n",
    "print(f\"üìä Colunas: {test_ds.column_names}\")\n",
    "\n",
    "# Testar processamento com num_proc=1\n",
    "print(\"\\nüîÑ Testando processamento com num_proc=1...\")\n",
    "processed_ds = test_ds.map(\n",
    "    prepare_fp_data,\n",
    "    fn_kwargs={\"reduce_ratio\": 0.5, \"krn_format\": \"bekern\"},\n",
    "    num_proc=1,  # Otimizado!\n",
    "    writer_batch_size=100,\n",
    "    load_from_cache_file=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Processamento conclu√≠do!\")\n",
    "print(f\"üìè Exemplo - Tamanho imagem: {processed_ds[0]['image'].shape}\")\n",
    "print(f\"üìù Exemplo - Tamanho transcri√ß√£o: {len(processed_ds[0]['transcription'])} tokens\")\n",
    "\n",
    "# Limpar mem√≥ria\n",
    "del test_ds, processed_ds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f36df2",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Iniciar Treinamento (Op√ß√£o 1: Script Otimizado)\n",
    "\n",
    "Use o script otimizado `train_kaggle.py` que j√° inclui todas as configura√ß√µes para 2 GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d67ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar usando o script otimizado\n",
    "# use_wandb=False para n√£o usar Weights & Biases (economiza tempo)\n",
    "# use_wandb=True se voc√™ tiver uma conta WandB configurada\n",
    "\n",
    "!python train_kaggle.py \\\n",
    "    --config_path=\"config/FP-GrandStaff/kaggle_config.json\" \\\n",
    "    --use_wandb=False \\\n",
    "    --max_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b451430",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Iniciar Treinamento (Op√ß√£o 2: C√≥digo Inline)\n",
    "\n",
    "Alternativamente, voc√™ pode treinar diretamente no notebook com controle total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import gc\n",
    "from data import SyntheticCLGrandStaffDataset\n",
    "from smt_trainer import SMT_Trainer\n",
    "from ExperimentConfig import experiment_config_from_dict\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.strategies import DDPStrategy\n",
    "\n",
    "# Configura√ß√µes\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Carregar configura√ß√£o\n",
    "with open('config/FP-GrandStaff/kaggle_config.json', \"r\") as f:\n",
    "    config = experiment_config_from_dict(json.load(f))\n",
    "\n",
    "print(\"üöÄ Iniciando treinamento otimizado para Kaggle...\")\n",
    "print(f\"üìä Batch size: {config.data.batch_size} (efetivo: {config.data.batch_size * 2 * 4} com 2 GPUs e grad accum)\")\n",
    "print(f\"üë∑ Workers: {config.data.num_workers}\")\n",
    "print(f\"üìê Reduce ratio: {config.data.reduce_ratio}\")\n",
    "\n",
    "# Carregar dados\n",
    "print(\"\\nüì• Carregando dataset...\")\n",
    "datamodule = SyntheticCLGrandStaffDataset(config=config.data, skip_steps=0)\n",
    "\n",
    "# Criar modelo\n",
    "max_height = datamodule.get_max_height()\n",
    "max_width = datamodule.get_max_width()\n",
    "max_len = datamodule.get_max_length()\n",
    "\n",
    "print(f\"\\nüìè Dimens√µes do modelo:\")\n",
    "print(f\"   Height: {max_height}, Width: {max_width}, Length: {max_len}\")\n",
    "\n",
    "model_wrapper = SMT_Trainer(\n",
    "    maxh=int(max_height), maxw=int(max_width), maxlen=int(max_len),\n",
    "    out_categories=len(datamodule.train_set.w2i), \n",
    "    padding_token=datamodule.train_set.w2i[\"<pad>\"],\n",
    "    in_channels=1, w2i=datamodule.train_set.w2i, i2w=datamodule.train_set.i2w,\n",
    "    d_model=256, dim_ff=256, num_dec_layers=8\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_SER\", min_delta=0.01, patience=10, mode=\"min\", verbose=True\n",
    ")\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    dirpath=config.checkpoint.dirpath,\n",
    "    filename=config.checkpoint.filename,\n",
    "    monitor=config.checkpoint.monitor,\n",
    "    mode=config.checkpoint.mode,\n",
    "    save_top_k=config.checkpoint.save_top_k,\n",
    "    verbose=True,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# Estrat√©gia multi-GPU\n",
    "strategy = DDPStrategy(\n",
    "    find_unused_parameters=False,\n",
    "    gradient_as_bucket_view=True\n",
    ")\n",
    "\n",
    "# Trainer otimizado\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    check_val_every_n_epoch=2,\n",
    "    callbacks=[checkpointer, early_stopping],\n",
    "    precision='16-mixed',\n",
    "    accelerator='gpu',\n",
    "    devices=2,  # 2 GPUs\n",
    "    strategy=strategy,\n",
    "    accumulate_grad_batches=4,  # Batch efetivo = 2*2*4 = 16\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=50,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüéÆ Configura√ß√£o do Trainer:\")\n",
    "print(f\"   GPUs: {trainer.num_devices}\")\n",
    "print(f\"   Batch efetivo: {config.data.batch_size * trainer.num_devices * trainer.accumulate_grad_batches}\")\n",
    "print(f\"   Precis√£o: {trainer.precision}\")\n",
    "\n",
    "# Treinar!\n",
    "print(\"\\nüöÄ Iniciando treinamento...\\n\")\n",
    "trainer.fit(model_wrapper, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cdf4e",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Avaliar Modelo\n",
    "\n",
    "Ap√≥s o treinamento, teste o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar o melhor modelo\n",
    "if checkpointer.best_model_path:\n",
    "    print(f\"üèÜ Carregando melhor modelo: {checkpointer.best_model_path}\")\n",
    "    best_model = SMT_Trainer.load_from_checkpoint(checkpointer.best_model_path)\n",
    "    \n",
    "    print(\"\\nüß™ Testando modelo...\")\n",
    "    test_results = trainer.test(best_model, datamodule=datamodule)\n",
    "    \n",
    "    print(\"\\n‚úÖ Resultados do teste:\")\n",
    "    for key, value in test_results[0].items():\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum checkpoint encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfbaa8",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Salvar e Baixar Checkpoints\n",
    "\n",
    "Salve os checkpoints para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar checkpoints salvos\n",
    "!ls -lh /kaggle/working/checkpoints/\n",
    "\n",
    "# Comprimir checkpoints para download\n",
    "!tar -czf checkpoints.tar.gz /kaggle/working/checkpoints/\n",
    "\n",
    "print(\"‚úÖ Checkpoints comprimidos em checkpoints.tar.gz\")\n",
    "print(\"üì• Voc√™ pode baixar o arquivo pela aba de Output do Kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d80b8d",
   "metadata": {},
   "source": [
    "## üîü Dicas e Troubleshooting\n",
    "\n",
    "### üí° Dicas para Otimiza√ß√£o\n",
    "\n",
    "1. **Se ficar sem mem√≥ria:**\n",
    "   - Reduza `batch_size` de 2 para 1\n",
    "   - Aumente `reduce_ratio` para 0.3 (imagens menores)\n",
    "   - Reduza `accumulate_grad_batches` de 4 para 2\n",
    "\n",
    "2. **Se o Map ainda travar:**\n",
    "   - J√° est√° com `num_proc=1` (otimizado)\n",
    "   - Cache habilitado com `load_from_cache_file=True`\n",
    "   - Se travar novamente, tente limpar o cache: `!rm -rf ~/.cache/huggingface/datasets/`\n",
    "\n",
    "3. **Para acelerar o treinamento:**\n",
    "   - Use `check_val_every_n_epoch=5` (validar menos frequentemente)\n",
    "   - Aumente `log_every_n_steps=100`\n",
    "   - Desabilite checkpoints intermedi√°rios: `save_top_k=1`\n",
    "\n",
    "4. **Monitoramento:**\n",
    "   - Use `!nvidia-smi` para ver uso de GPU\n",
    "   - Use `!htop` para ver uso de CPU/RAM\n",
    "\n",
    "### ‚ö†Ô∏è Problemas Comuns\n",
    "\n",
    "**Problema**: Map freezando em 9%\n",
    "- **Solu√ß√£o**: J√° aplicada! `num_proc=1` e cache habilitado\n",
    "\n",
    "**Problema**: Out of Memory (OOM)\n",
    "- **Solu√ß√£o**: Reduza batch_size ou reduce_ratio\n",
    "\n",
    "**Problema**: GPUs n√£o sendo usadas\n",
    "- **Solu√ß√£o**: Verifique `devices=2` e `accelerator='gpu'` no Trainer\n",
    "\n",
    "**Problema**: Treinamento muito lento\n",
    "- **Solu√ß√£o**: Verifique se `precision='16-mixed'` est√° habilitado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b528e19",
   "metadata": {},
   "source": [
    "## üìä Resumo das Otimiza√ß√µes Aplicadas\n",
    "\n",
    "### ‚úÖ Melhorias no C√≥digo Base\n",
    "\n",
    "| Arquivo | Mudan√ßa | Antes | Depois | Impacto |\n",
    "|---------|---------|-------|--------|---------|\n",
    "| `data.py` | num_proc reduzido | 4-8 | 1 | ‚ö° Evita overhead e travamento |\n",
    "| `data.py` | writer_batch_size | 500/32 | 100 | üíæ Reduz uso de mem√≥ria |\n",
    "| `data.py` | Cache habilitado | ‚ùå | ‚úÖ | ‚ö° Reutiliza processamento |\n",
    "| `SynthGenerator.py` | num_proc reduzido | 8 | 1 | ‚ö° Evita overhead |\n",
    "| `configs` | num_workers | 20 | 4 | ‚ö° Balanceado para 2 GPUs |\n",
    "| `configs` | batch_size | 1 | 2 | ‚ö° Melhor aproveitamento GPU |\n",
    "| `configs` | reduce_ratio | 1.0 | 0.5 | üíæ Imagens 50% menores |\n",
    "\n",
    "### ‚úÖ Otimiza√ß√µes no Trainer\n",
    "\n",
    "- **Multi-GPU**: DDP Strategy para 2 GPUs\n",
    "- **Mixed Precision**: 16-bit (economiza ~50% de mem√≥ria)\n",
    "- **Gradient Accumulation**: 4 steps (batch efetivo = 16)\n",
    "- **Gradient Clipping**: 1.0 (estabiliza treinamento)\n",
    "- **Early Stopping**: Patience 10 √©pocas\n",
    "- **Checkpointing**: Top-2 + √∫ltimo modelo\n",
    "\n",
    "### üéØ Resultado Esperado\n",
    "\n",
    "Com estas otimiza√ß√µes:\n",
    "- ‚úÖ Map n√£o deve mais travar\n",
    "- ‚úÖ Uso de mem√≥ria otimizado (30GB RAM + 2x GPU)\n",
    "- ‚úÖ Treinamento ~2-3x mais r√°pido\n",
    "- ‚úÖ Batch efetivo maior = melhor converg√™ncia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8efa5a3",
   "metadata": {},
   "source": [
    "## üì§ Git: Fazer Push das Otimiza√ß√µes\n",
    "\n",
    "Use esta c√©lula se voc√™ estiver trabalhando localmente e quiser fazer push das altera√ß√µes para o GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure suas credenciais Git (apenas na primeira vez)\n",
    "# !git config --global user.email \"seu_email@example.com\"\n",
    "# !git config --global user.name \"Seu Nome\"\n",
    "\n",
    "# Adicionar todas as altera√ß√µes\n",
    "!git add data.py SynthGenerator.py train_kaggle.py config/ KAGGLE_OPTIMIZATIONS.md kaggle_training_notebook.ipynb\n",
    "\n",
    "# Fazer commit\n",
    "!git commit -m \"‚ú® Otimiza√ß√µes para Kaggle: fix Map freeze, multi-GPU, memory optimization\"\n",
    "\n",
    "# Push para o reposit√≥rio\n",
    "!git push origin main\n",
    "\n",
    "print(\"‚úÖ Altera√ß√µes enviadas para o GitHub!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
